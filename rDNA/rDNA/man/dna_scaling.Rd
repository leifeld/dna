% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dna_scale.R
\name{dna_scale1dbin}
\alias{dna_scale1dbin}
\alias{dna_scale1dord}
\alias{dna_scale2dbin}
\alias{dna_scale2dord}
\alias{print.dna_scale}
\alias{autoplot.dna_scale}
\title{Ideological scaling for discourse networks using item response theory}
\usage{
dna_scale1dbin(
  statementType = "DNA Statement",
  variable1 = "organization",
  variable2 = "concept",
  qualifier = "agreement",
  zero_as_na = TRUE,
  threshold = NULL,
  theta_constraints = NULL,
  mcmc_iterations = 20000,
  mcmc_burnin = 1000,
  mcmc_thin = 10,
  mcmc_normalize = FALSE,
  theta_start = NA,
  alpha_start = NA,
  beta_start = NA,
  theta_prior_mean = 0,
  theta_prior_variance = 1,
  alpha_beta_prior_mean = 0,
  alpha_beta_prior_variance = 0.25,
  store_variables = "both",
  drop_constant_concepts = FALSE,
  drop_min_actors = 1,
  drop_min_concepts = 2,
  verbose = TRUE,
  seed = 12345,
  ...
)

dna_scale1dord(
  statementType = "DNA Statement",
  variable1 = "organization",
  variable2 = "concept",
  qualifier = "agreement",
  zero_as_na = TRUE,
  threshold = NULL,
  lambda_constraints = NULL,
  mcmc_iterations = 20000,
  mcmc_burnin = 1000,
  mcmc_thin = 10,
  mcmc_tune = 1.5,
  mcmc_normalize = FALSE,
  lambda_start = NA,
  lambda_prior_mean = 0,
  lambda_prior_variance = 1,
  store_variables = "both",
  drop_constant_concepts = FALSE,
  drop_min_actors = 1,
  drop_min_concepts = 2,
  verbose = TRUE,
  seed = 12345,
  ...
)

dna_scale2dbin(
  statementType = "DNA Statement",
  variable1 = "organization",
  variable2 = "concept",
  qualifier = "agreement",
  zero_as_na = TRUE,
  threshold = NULL,
  item_constraints = NULL,
  mcmc_iterations = 20000,
  mcmc_burnin = 1000,
  mcmc_thin = 10,
  alpha_beta_start = NA,
  alpha_beta_prior_mean = 0,
  alpha_beta_prior_variance = 0.1,
  store_variables = "both",
  drop_constant_concepts = FALSE,
  drop_min_actors = 1,
  drop_min_concepts = 2,
  verbose = TRUE,
  seed = 12345,
  ...
)

dna_scale2dord(
  statementType = "DNA Statement",
  variable1 = "organization",
  variable2 = "concept",
  qualifier = "agreement",
  zero_as_na = TRUE,
  threshold = NULL,
  lambda_constraints = NULL,
  mcmc_iterations = 20000,
  mcmc_burnin = 1000,
  mcmc_thin = 10,
  mcmc_tune = 1.5,
  lambda_start = NA,
  lambda_prior_mean = 0,
  lambda_prior_variance = 0.1,
  store_variables = "both",
  drop_constant_concepts = FALSE,
  drop_min_actors = 1,
  drop_min_concepts = 2,
  verbose = TRUE,
  seed = 12345,
  ...
)

\method{print}{dna_scale}(x, trim = 60, ...)

\method{autoplot}{dna_scale}(
  object,
  ...,
  type = c("trace", "density", "scaling"),
  parameters = c("ability", "discrimination", "difficulty"),
  trim = 40,
  nrow = 5,
  ncol = 3
)
}
\arguments{
\item{statementType}{The statement type as a character object.}

\item{variable1}{The first variable for the scaling construction (see
\link{dna_network}). Defaults to \code{"organization"}.}

\item{variable2}{The second variable for the scaling construction (see
\link{dna_network}). Defaults to \code{"concept"}.}

\item{qualifier}{The qualifier variable for the scaling construction (see
\link{dna_network}). Defaults to \code{"agreement"}. If you did not use
a qualifier in the coding, you can set the qualifier to be the same value
as variable2 and estimate an ordinal model with argument
\code{zero_as_na = FALSE} (because non-mentions of concepts are interpreted
as \code{NA} in the binary model).}

\item{zero_as_na}{Logical. Only ordinal models. If \code{TRUE}, all
non-mentions of an actor towards a concept will be recoded as \code{NA}. If
\code{FALSE} as \code{2}.}

\item{threshold}{Numeric value that specifies when a mixed position can be
considered as agreement or disagreement. If, for example, one actor has 60
percent of agreeing and 40 percent of disagreeing statements towards a
concept, a \code{threshold} of 0.51 will recode the actor position on this
concept as "agreement". The same accounts also for disagreeing statements.
If one actor has 60 percent of disagreeing and 40 percent of agreeing
statements, a \code{threshold} of 0.51 will recode the actor position on
this concept as "disagreement". All values in between the \code{threshold}
(e.g., 55 percent agreement and 45 percent of disagreement and a threshold
of 0.6) will be recoded as \code{NA}. If is set to \code{NULL}, all "mixed"
positions of actors will be recoded as \code{NA}. Must be strictly
positive.}

\item{theta_constraints}{A list specifying the constraints on the actor
parameter in a one-dimensional binary model. Three forms of constraints are
possible: \code{actorname = value}, which will constrain an actor to be
equal to the specified value (e.g. \code{0}), \code{actorname = "+"}, which
will constrain the actor to be positively scaled and
\code{actorname = "-"}, which will constrain the actor to be negatively
scaled (see example).}

\item{mcmc_iterations}{The number of iterations for the sampler (not
including the burn-in iterations, which are discarded) before thinning.}

\item{mcmc_burnin}{The number of burn-in iterations for the sampler, which
are discarded.}

\item{mcmc_thin}{The thinning interval for the sampler. Iterations must be
divisible by the thinning interval. The final number of samples retained in
the output equals \code{(mcmc_iterations - mcmc_burnin) / mcmc_thin}.}

\item{mcmc_normalize}{Logical. Should the MCMC output be normalized? If
\code{TRUE}, samples are normalized to a mean of \code{0} and a standard
deviation of \code{1}.}

\item{theta_start}{The starting values for the actor parameters in a
one-dimensional binary model. Can either be a scalar or a column vector
with as many elements as the number of actors included in the scaling. If
set to the default \code{NA}, starting values will be set according to an
eigenvalue-eigenvector decomposition of the actor agreement score.}

\item{alpha_start}{The starting values for the concept difficulty
parameters in a one-dimensional binary model. Can either be a scalar or a
column vector with as many elements as the number of items included in the
scaling. If set to the default \code{NA}, starting values will be set
according to a series of probit regressions that condition the starting
values of the difficulty parameters.}

\item{beta_start}{The starting values for the concept discrimination
parameters in a one-dimensional binary model. Can either be a scalar or a
column vector with as many elements as the number of items included in the
scaling. If set to the default \code{NA}, starting values will be set
according to a series of probit regressions that condition the starting
values of the discrimination parameters.}

\item{theta_prior_mean}{A scalar value specifying the prior mean of the
actor parameters in a one-dimensional binary model.}

\item{theta_prior_variance}{A scalar value specifying the prior inverse
variances of the actor parameters in a one-dimensional binary model.}

\item{alpha_beta_prior_mean}{Mean of the difficulty and discrimination
parameters in a one- or two-dimensional binary model. Can either be a
scalar or a vector of length two. If a scalar, both means will be set
according to the specified value.}

\item{alpha_beta_prior_variance}{Inverse variance of the difficulty and
discrimination parameters in a one- or two-dimensional binary model. Can
either be a scalar or a vector of length two. If a scalar, both means will
be set according to the specified value.}

\item{store_variables}{A character vector indicating which variables should
be stored from the scaling. Can either take the value of the character
vector indicated in \code{variable1} or \code{variable2} or \code{"both"}
to store both variables. Note that saving both variables can impact the
speed of the scaling. Defaults to \code{"both"}.}

\item{drop_constant_concepts}{Logical. Should concepts that have no
variation be deleted before the scaling? Defaults to \code{FALSE}.}

\item{drop_min_actors}{A numeric value specifying the minimum number of
concepts actors should have mentioned to be included in the scaling.
Defaults to \code{1}.}

\item{drop_min_concepts}{A numeric value specifying the minimum number a
concept should have been jointly mentioned by actors. Defaults to \code{2}.}

\item{verbose}{A boolean or numeric value indicating whether the iterations
of the scaling should be printed to the R console. If set to a numeric
value, every \code{verboseth} iteration will be printed. If set to
\code{TRUE}, \code{verbose} will print the total of iterations and burn-in
divided by \code{10}.}

\item{seed}{The random seed for the scaling.}

\item{...}{Additional arguments passed to \link{dna_network}. Actors can, for
example, be removed with the \code{excludeValues} arguments. The scaling
can also be applied to a specific time slice by using \code{start.date} and
\code{stop.date}. For the \code{autoplot} method, this argument is not in
use.}

\item{lambda_constraints}{A list of lists specifying constraints on the
concept parameters in an ordinal model. Note that value \code{1} in the
brackets of the argument refers to the negative item difficulty parameters,
which in general should not be constrained. Value \code{2} relates to the
item discrimination parameter and should be used for constraints on
concepts. Three forms of constraints are possible:
\code{conceptname = list(2, value)} will constrain the item discrimination
parameter to be equal to the specified value (e.g., 0).
\code{conceptname = list(2,"+")} will constrain the item discrimination
parameter to be positively scaled and \code{conceptname = list(2, "-")}
will constrain the parameter to be negatively scaled (see example).}

\item{mcmc_tune}{Only ordinal models. The tuning parameter for the acceptance
rates of the sampler. Acceptance rates should ideally range between
\code{0.15} and \code{0.5}. Can be either a scalar or a k-vector. Must be
strictly positive.}

\item{lambda_start}{The starting values for the concept discrimination
parameters in an ordinal model. Can be either a scalar or a matrix. If set
to \code{NA} (default), the \code{starting values} for the unconstrained
parameters in the first column are based on the observed response pattern.
The remaining unconstrained elements are set to \code{starting values} of
either \code{1.0} or \code{-1.0}, depending on the nature of the
constraint.}

\item{lambda_prior_mean}{The prior mean of the concept discrimination
parameters in an ordinal model. Can be either a scalar or a matrix.}

\item{lambda_prior_variance}{The prior inverse variances of the concept
discrimination parameters in an ordinal model. Can be either a scalar or a
matrix.}

\item{item_constraints}{A list of lists specifying constraints on the
concept parameters in a two-dimensional binary model. Note that value
\code{1} in the brackets of the argument refers to the item difficulty
parameters, which in general should not be constrained. All values above
\code{1} relate to the item discrimination parameters on the single
dimensions. These should be used for constraints on concepts. Three forms
of constraints are possible: \code{conceptname = list(2, value)} will
constrain a concept to be equal to the specified value (e.g., 0) on the
first dimension of the item discrimination parameter.
\code{conceptname = list(2,"+")} will constrain the concept to be
positively scaled on the first dimension and
\code{conceptname = list(2, "-")} will constrain the concept to be
negatively scaled on the first dimension (see example). If you
wish to constrain a concept on the second dimension, please indicate this
with a \code{3} in the first position in the bracket.}

\item{alpha_beta_start}{The starting values for the concept difficulty and
discrimination parameters in a two-dimensional binary model. Can either be
a scalar or a column vector with as many elements as the number of items
included in the scaling. If set to the default \code{NA}, starting values
will be set according to a series of probit regressions that condition the
starting values of the difficulty and discrimination parameters.}

\item{x}{A \code{dna_scale} object.}

\item{trim}{An integer defining the maximum length of the labels.}

\item{object}{A \code{dna_scale} object, created by one of the scaling functions.}

\item{type}{The type(s) of plot to generate. Must be one or more of the following:
\itemize{
  \item \code{"trace"}: For creating MCMC trace plots.
  \item \code{"density"}: For creating MCMC density plots.
  \item \code{"scaling"}: For creating plots summarizing the estimated parameters.
}}

\item{parameters}{The parameter type(s) to plot. Must be one or more of the following:
\itemize{
  \item \code{"ability"}: The ability parameters for the actors, indicating their ideology.
  \item \code{"discrimination"}: The item discrimination parameters.
  \item \code{"difficulty"}: The item difficulty parameters.
}}

\item{nrow}{An integer defining how many rows of parameters should be in a trace or density plot.}

\item{ncol}{An integer defining how many columns of parameters should be in a trace or density plot.}
}
\description{
One- or two-dimensional binary or ordinal IRT scaling for DNA.
}
\section{Overview}{

This set of functions applies item response theory (IRT) to discourse
networks to scale actors and concepts on an underlying ideological scale.
Four estimation functions are available:
\itemize{
  \item \code{dna_scale1dbin} Binary scaling in one dimension.
  \item \code{dna_scale2dbin} Binary scaling in two dimensions.
  \item \code{dna_scale1dord} Ordinal scaling in one dimension.
  \item \code{dna_scale2dord} Ordinal scaling in two dimensions.
}
These functions are convenience wrappers for the \code{MCMCirt1d},
\code{MCMCirtKd}, and \code{MCMCordfactanal} functions in the MCMCpack
package, which use Markov Chain Monte Carlo (MCMC) methods to generate
posterior samples of ability, discrimination, and difficulty parameters.

The corresponding \code{print} function prints the formatted posterior means
and HPD intervals to the console. The autoplot function plots the MCMC trace,
density, and summaries of estimates with the help of the \pkg{ggplot2}
package.
}

\section{Model interpretation}{

One parameter for each actor and two parameters for each concept are
estimated:
\itemize{
  \item Ability parameter: The estimated ability parameter indicates an
    actor's ideological position on a left-right scale (e.g., industry vs.
    environment, labor vs. capital, containing vs. expanding regulation etc.)
    or on two dimensions. It is denoted as theta (\eqn{\theta}) in the binary
    model and phi (\eqn{\phi}) in the ordinal model in this implementation.
  \item Discrimination parameter: The estimated  discrimination parameter
    indicates a concept's ability to discriminate between actors on their
    left-right scale. The discrimination parameter measures how well an item
    can distinguish between actors with different levels of the latent trait
    (in this case, ideology). It reflects how strongly the item is related
    to the underlying trait being measured. A high discrimination parameter
    means that the item is very effective at differentiating between
    individuals who have slightly different levels of the underlying
    ideology. For instance, a highly discriminatory question will sharply
    differentiate between actors on either side of an ideological spectrum
    (e.g., conservative vs. liberal). A higher discrimination value indicates
    that the item is more sensitive to changes in the latent trait
    (ideology). A low discrimination value suggests that the item does not
    differentiate well between actors with different levels of ideology. In
    the notation used in this implementation, the discrimination parameter is
    denoted as beta (\eqn{\beta}) in the binary model and Lambda 2
    (\eqn{\Lambda_2}) in the ordinal model, though elsewhere in the literature
    it is often denoted as alpha (\eqn{\alpha}).
  \item Difficulty parameter: The difficulty parameter for a concept
    represents the location of the item along the ideological spectrum. The
    difficulty parameter helps determine where on the ideological spectrum a
    particular item is situated. For instance, an item with a high difficulty
    parameter might represent a position that only those with a
    strong ideological stance (e.g., very liberal or very conservative) are
    likely to endorse. An item with a low difficulty parameter would be
    endorsed by most actors, indicating that the statement is relatively easy
    to agree with (possibly a moderate or widely accepted stance).
    Conversely, an item with a high difficulty parameter would only be
    endorsed by those with a more extreme position on the ideology being
    measured. In the notation used in this implementation, the difficulty
    parameter is denoted as alpha (\eqn{\alpha}) in the binary model and as
    Lambda 1 (\eqn{\Lambda_1}) in the ordinal model, though elsewhere in the
    literature it is often denoted as beta (\eqn{\beta}).
}
See the help pages of the \code{MCMCirt1d} function (for the binary model)
and the \code{MCMCordfactanal} (for the ordinal model) for details on the
functional form and parameterization of the mdoel, which is a slight
deviation from the standard 2PL model.
}

\section{Variable coding}{

As in a two-mode network in \link{dna_network}, two variables have to be
provided for the scaling. The first variable corresponds to the rows of a
two-mode network and usually entails actors (e.g., \code{"organizations"}),
while the second variable is equal to the columns of a two-mode network,
typically expressed by \code{"concepts"}. The \code{dna_scale} functions
use \code{"actors"} and \code{"concepts"} as synonyms for \code{variable1}
and \code{variable2}. However, the scaling is not restricted to
\code{"actors"} and \code{"concepts"} but depends on what you provide in
\code{variable1} or \code{variable2}.
}

\section{Binary models}{

Binary models recode two-mode network matrices into zeroes and ones and then
estimate a logit model for binary data. The network cells are recoded using
the following rules:
\itemize{
  \item For a binary qualifier, \code{dna_scale1dbin} internally uses the
    \code{combine} qualifier aggregation and then recodes the values into
    \code{0} for disagreement, \code{1} for agreement, and \code{NA} for
    mixed positions and non-mentions of concepts. If
    \code{zero_as_na = FALSE} is set, the mixed positions and non-mentions
    become \code{0} instead of \code{NA} and are treated as informative.
  \item If no qualifier is used or the qualifier variable is categorical,
    non-mentions become \code{0} and any number of mentions become \code{1}.
    \code{zero_as_na} must be \code{FALSE} in this case.
  \item If a threshold is used (e.g., \code{0.4}), the fraction of positive
    mentions over the sum of both positive and negative mentions, which
    scales between \code{0} and \code{1}, is used to recode fractions smaller
    than or equal to the threshold as \code{0}, values larger than or equal
    to one minus the threshold as \code{1}, and values between the threshold
    and one minus the threshold as \code{NA}. For example, if an actor
    mentions a concept six times in a positive way and five times in a
    negative way, the fraction of positive mentions is \code{6 / 11 = 0.54}.
    If a threshold of \code{0.4} is used (or, equivalently, \code{0.6}), the
    value is recoded to \code{NA}. If no threshold is used, the value becomes
    \code{1}.
  \item Integer qualifiers are also recoded into \code{0} and \code{1} by
    rescaling the qualifier values between \code{0} and \code{1}. Thresholds
    larger than \code{0} and smaller than \code{1} are possible here as well.
}
}

\section{Ordinal models}{

Ordinal models recode two-mode network matrices into values \code{1},
\code{2}, or \code{3} and then estimate an ordinal latent factor model for
ordinal data, which corresponds to ordinal item response theory. The network
cells are recoded using the following rules:
\itemize{
  \item For a binary qualifier, \code{dna_scale1dord} internally uses the
    \code{combine} qualifier aggregation and then recodes the values into
    \code{1} for disagreement, \code{2} for ambivalent positions with both
    positive and negative mentions, \code{3} for exclusively positive
    mentions, and \code{NA} for non-mentions. If \code{zero_as_na = FALSE} is
    set, non-mentions are recoded as \code{2} as well and thereby become
    informative as neutral positions.
  \item If no qualifier is used or the qualifier variable is categorical,
    non-mentions become \code{0} and any number of mentions become \code{1}.
    \code{zero_as_na} must be \code{FALSE} in this case.
  \item If a threshold is used, the same recoding procedure as in the binary
    model is used, but values below or equal to the threshold become
    \code{1}, values above the threshold and below one minus the threshold
    become \code{2}, values equal to or above the threshold become \code{3},
    and non-mentions are coded as \code{NA} (unless
    \code{zero_as_na = FALSE}).
  \item Integer qualifiers are also recoded into three positive integer
    values by rescaling the qualifier values between \code{0} and \code{1}.
    Thresholds larger than \code{0} and smaller than \code{1} are possible
    here as well.
}
In ordinal models, threshold parameters are estimated alongside the other
parameters, like in other ordinal logit models. They are treated as nuisance
parameters and not reported in the output. However, they are stored in the
object as part of the posterior samples and can be retrieved if necessary.
}

\section{Tweaking the estimation}{

As these functions implement a Bayesian Item Response Theory approach,
\code{priors} and \code{starting values} can be set on the actor and concept
parameters. Changing the default \code{prior} values can often help you to
achieve better results. Constraints on the actor parameters can also be
specified to help identifying the model and to indicate in which direction
ideological positions of actors and concepts run. The returned MCMC output
can also be post-processed by normalizing the samples for each iteration with
\code{mcmc_normalize}. Normalization can be a sufficient way of identifying
one-dimensional ideal point models.

Unlike \link{dna_scale1dbin}, \link{dna_scale2dbin} constrains the values
indicated in \code{variable2}. For these values, the scaling estimates an
item discrimination parameter for each dimension and an item difficulty
parameter for both dimensions. The item difficulty parameter should,
however, not be constrained (see \link[MCMCpack]{MCMCirtKd}). Therefore, you
should set constraints on the item discrimination parameters.

Fitting two-dimensional scaling models requires a good choice of concept
constraints to specify the ideological dimensions of your data. A suitable
way of identifying your ideological dimensions is to constrain one item
discrimination parameter to load only on one dimension. This means that we
set one parameter to load either positive or negative on one dimension and
setting it to zero on the other. A second concept should also be constrained
to load either positive or negative on one dimension (see example).

The argument \code{drop_min_actors} excludes actors with only a limited
number of concepts used. Limited participation of actors in a debate can
impact the scaling of the ideal points, as actors with only few mentions of
concepts convey limited information on their ideological position. The same
can also be done for concepts with the argument \code{drop_min_concepts}.
Concepts that have been rarely mentioned do not strongly discriminate the
ideological positions of actors and can, therefore, impact the accuracy of
the scaling. Reducing the number of actors of concepts to be scaled hence
improves the precision of the ideological positions for both variables and
the scaling itself. Another possibility to reduce the number of concepts is
to use \code{drop_constant_concepts}, which will reduce concepts not having
any variation in the agreement/disagreement structure of actors. This means
that all concepts will be dropped which have only agreeing or disagreeing
statements.
}

\examples{
\dontrun{
library("rDNA")
library("ggplot2")
library("ggrepel")

dna_init()
dna_openDatabase(dna_sample(overwrite = TRUE), coderPassword = "sample")

# one-dimensional binary model
fit_1d_bin <- dna_scale1dbin(
  variable1 = "organization",
  variable2 = "concept",
  qualifier = "agreement",
  threshold = 0.49,
  theta_constraints = list(
    `National Petrochemical & Refiners Association` = "+",
    `Alliance to Save Energy` = "-"),
  mcmc_iterations = 20000,
  mcmc_burnin = 2000,
  mcmc_thin = 10,
  mcmc_normalize = TRUE,
  theta_prior_mean = 0,
  theta_prior_variance = 1,
  alpha_beta_prior_mean = 0,
  alpha_beta_prior_variance = 0.25,
  store_variables = "both",
  drop_constant_concepts = FALSE,
  drop_min_actors = 1,
  verbose = TRUE,
  seed = 12345
)
fit_1d_bin
autoplot(fit_1d_bin)

# two-dimensional binary model
fit_2d_bin <- dna_scale2dbin(
  variable1 = "organization",
  variable2 = "concept",
  qualifier = "agreement",
  threshold = 0.4,
  item_constraints = list(
    `Climate change is caused by greenhouse gases (CO2).` = list(2, "-"),
    `Climate change is caused by greenhouse gases (CO2).` = c(3, 0),
    `CO2 legislation will not hurt the economy.` = list(3, "-")),
  mcmc_iterations = 20000,
  mcmc_burnin = 2000,
  mcmc_thin = 10,
  alpha_beta_prior_mean = 0,
  alpha_beta_prior_variance = 1,
  store_variables = "organization",
  drop_constant_concepts = TRUE,
  verbose = TRUE,
  seed = 12345
)
fit_2d_bin
autoplot(fit_2d_bin)

# one-dimensional ordinal model
fit_1d_ord <- dna_scale1dord(
  variable1 = "organization",
  variable2 = "concept",
  qualifier = "agreement",
  zero_as_na = TRUE,
  threshold = 0.4,
  lambda_constraints = list(`CO2 legislation will not hurt the economy.` = list(2, "-")),
  mcmc_iterations = 20000,
  mcmc_burnin = 2000,
  mcmc_thin = 10,
  mcmc_tune = 1.5,
  mcmc_normalize = FALSE,
  lambda_prior_mean = 0,
  lambda_prior_variance = 0.1,
  store_variables = "organization",
  drop_constant_concepts = TRUE,
  verbose = TRUE,
  seed = 12345
)
fit_1d_ord
autoplot(fit_1d_ord)

# two-dimensional ordinal model
fit_2d_ord <- dna_scale2dord(
  variable1 = "organization",
  variable2 = "concept",
  qualifier = "agreement",
  zero_as_na = TRUE,
  threshold = 0.4,
  lambda_constraints = list(
    `Climate change is caused by greenhouse gases (CO2).` = list(2, "-"),
    `Climate change is caused by greenhouse gases (CO2).` = list(3, 0),
    `CO2 legislation will not hurt the economy.` = list(3, "-")),
  mcmc_iterations = 20000,
  mcmc_burnin = 2000,
  mcmc_thin = 10,
  mcmc_tune = 1.5,
  lambda_prior_mean = 0,
  lambda_prior_variance = 0.1,
  store_variables = "both",
  drop_constant_concepts = TRUE,
  verbose = TRUE,
  seed = 12345
)
fit_2d_ord
autoplot(fit_2d_ord)
}

}
\author{
Tim Henrichsen, Philip Leifeld, Johannes B. Gruber
}
